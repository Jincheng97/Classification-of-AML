{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = './AMLTraining.csv'\n",
    "all_label = pd.read_csv(label_path)\n",
    "files = os.listdir('./CSV/')\n",
    "\n",
    "take_test_data = 1000\n",
    "for i in range(len(all_label)):\n",
    "    if (all_label.iloc[i]['Label'] != 'normal') & (all_label.iloc[i]['Label'] != 'aml'):\n",
    "        test_file_start = i\n",
    "        break\n",
    "x1_test = pd.read_csv('./CSV/' + files[test_file_start]).iloc[:take_test_data]\n",
    "x2_test = pd.read_csv('./CSV/' + files[test_file_start + 1]).iloc[:take_test_data]\n",
    "x3_test = pd.read_csv('./CSV/' + files[test_file_start + 2]).iloc[:take_test_data]\n",
    "x4_test = pd.read_csv('./CSV/' + files[test_file_start + 3]).iloc[:take_test_data]\n",
    "x5_test = pd.read_csv('./CSV/' + files[test_file_start + 4]).iloc[:take_test_data]\n",
    "x6_test = pd.read_csv('./CSV/' + files[test_file_start + 5]).iloc[:take_test_data]\n",
    "x7_test = pd.read_csv('./CSV/' + files[test_file_start + 6]).iloc[:take_test_data]\n",
    "x8_test = pd.read_csv('./CSV/' + files[test_file_start + 7]).iloc[:take_test_data]\n",
    "    \n",
    "for file_num, each_file in enumerate(files):\n",
    "    if file_num >= test_file_start + 8:\n",
    "        if file_num % 8 == 0:\n",
    "            x1_test = pd.concat([x1_test, pd.read_csv('./CSV/' + each_file)[:take_test_data]])\n",
    "        if file_num % 8 == 1:\n",
    "            x2_test = pd.concat([x2_test, pd.read_csv('./CSV/' + each_file)[:take_test_data]])\n",
    "        if file_num % 8 == 2:\n",
    "            x3_test = pd.concat([x3_test, pd.read_csv('./CSV/' + each_file)[:take_test_data]])\n",
    "        if file_num % 8 == 3:\n",
    "            x4_test = pd.concat([x4_test, pd.read_csv('./CSV/' + each_file)[:take_test_data]])\n",
    "        if file_num % 8 == 4:\n",
    "            x5_test = pd.concat([x5_test, pd.read_csv('./CSV/' + each_file)[:take_test_data]])\n",
    "        if file_num % 8 == 5:\n",
    "            x6_test = pd.concat([x6_test, pd.read_csv('./CSV/' + each_file)[:take_test_data]])\n",
    "        if file_num % 8 == 6:\n",
    "            x7_test = pd.concat([x7_test, pd.read_csv('./CSV/' + each_file)[:take_test_data]])\n",
    "        if file_num % 8 == 7:\n",
    "            x8_test = pd.concat([x8_test, pd.read_csv('./CSV/' + each_file)[:take_test_data]])\n",
    "\n",
    "x1_test['FS Lin'] = scale(x1_test['FS Lin'])\n",
    "x2_test['FS Lin'] = scale(x2_test['FS Lin'])\n",
    "x3_test['FS Lin'] = scale(x3_test['FS Lin'])\n",
    "x4_test['FS Lin'] = scale(x4_test['FS Lin'])\n",
    "x5_test['FS Lin'] = scale(x5_test['FS Lin'])\n",
    "x6_test['FS Lin'] = scale(x6_test['FS Lin'])\n",
    "x7_test['FS Lin'] = scale(x7_test['FS Lin'])\n",
    "x8_test['FS Lin'] = scale(x8_test['FS Lin'])\n",
    "\n",
    "# x1_test.to_csv('x1_test.csv', index = False)\n",
    "# x2_test.to_csv('x2_test.csv', index = False)\n",
    "# x3_test.to_csv('x3_test.csv', index = False)\n",
    "# x4_test.to_csv('x4_test.csv', index = False)\n",
    "# x5_test.to_csv('x5_test.csv', index = False)\n",
    "# x6_test.to_csv('x6_test.csv', index = False)\n",
    "# x7_test.to_csv('x7_test.csv', index = False)\n",
    "# x8_test.to_csv('x8_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1_test = pd.read_csv('x1_test.csv')\n",
    "# x2_test = pd.read_csv('x2_test.csv')\n",
    "# x3_test = pd.read_csv('x3_test.csv')\n",
    "# x4_test = pd.read_csv('x4_test.csv')\n",
    "# x5_test = pd.read_csv('x5_test.csv')\n",
    "# x6_test = pd.read_csv('x6_test.csv')\n",
    "# x7_test = pd.read_csv('x7_test.csv')\n",
    "# x8_test = pd.read_csv('x8_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict({'input1': x1_test, 'input2': x2_test, 'input3': x3_test, 'input4': x4_test, \\\n",
    "                        'input5': x5_test, 'input6': x6_test, 'input7': x7_test, 'input8': x8_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 203 is AML. Confidence: 0.979\n",
      "Subject 205 is AML. Confidence: 0.991\n",
      "Subject 211 is AML. Confidence: 0.991\n",
      "Subject 219 is AML. Confidence: 0.9299999999999999\n",
      "Subject 221 is AML. Confidence: 0.993\n",
      "Subject 227 is AML. Confidence: 0.994\n",
      "Subject 236 is AML. Confidence: 0.654\n",
      "Subject 239 is AML. Confidence: 0.7070000000000001\n",
      "Subject 250 is AML. Confidence: 0.542\n",
      "Subject 261 is AML. Confidence: 0.9390000000000001\n",
      "Subject 262 is AML. Confidence: 0.999\n",
      "Subject 269 is AML. Confidence: 0.987\n",
      "Subject 284 is AML. Confidence: 0.964\n",
      "Subject 285 is AML. Confidence: 0.956\n",
      "Subject 299 is AML. Confidence: 0.991\n",
      "Subject 314 is AML. Confidence: 0.998\n",
      "Subject 326 is AML. Confidence: 0.911\n",
      "Subject 337 is AML. Confidence: 0.984\n",
      "Subject 344 is AML. Confidence: 0.733\n",
      "Subject 348 is AML. Confidence: 0.999\n",
      "There are 20 AML subjects in total.\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "confidence = []\n",
    "aml_count = 0\n",
    "for subject_num in range(180):\n",
    "    normal_vote_count = 0\n",
    "    for data_num in range(take_test_data):\n",
    "        if result[subject_num*take_test_data + data_num][0] < result[subject_num*take_test_data + data_num][1]:\n",
    "            normal_vote_count += 1\n",
    "    if normal_vote_count > take_test_data/2:\n",
    "        prediction.append('normal')\n",
    "    else:\n",
    "        prediction.append('aml')\n",
    "        aml_count += 1\n",
    "        print('Subject ' + str(180 + subject_num) + ' is AML. Confidence: ' + str(1 - normal_vote_count/take_test_data))\n",
    "    confidence.append(normal_vote_count/take_test_data)\n",
    "print('There are ' + str(aml_count) + ' AML subjects in total.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinch\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "label_prediction = all_label\n",
    "for i in range(len(prediction)):\n",
    "    label_prediction.iloc[(179 + i)*8:(179 + i)*8 + 8]['Label'] = prediction[i]\n",
    "label_prediction.to_csv('./AMLPrediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
